{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### Astropy\n",
    "import astropy\n",
    "\n",
    "#Astropy FITS/Table handling\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOKASC_cat_v6.6.1.fits.gz            \u001b[34m__pycache__\u001b[m\u001b[m/\r\n",
      "CarreraLike.ipynb                     age2age.pdf\r\n",
      "LMC_Ages.ipynb                        age2age_PCA_OLS.pdf\r\n",
      "LMC_DR16_all_PDF.fits.gz              age2age_PCA_OLS2.pdf\r\n",
      "MADdist.pdf                           age_functions.py\r\n",
      "MagellanicStream.py                   agemap.jpg\r\n",
      "PCAOLS_uncert.pdf                     b.txt\r\n",
      "PCAOLS_uncert2.pdf                    depPCAthenOLS.ipynb\r\n",
      "PCAandOLS.ipynb                       housing.csv\r\n",
      "README.md                             lmc_rgbmembers.r13-l33-58672.fits.gz\r\n",
      "StellAANN.ipynb                       logisochrones.dat\r\n",
      "TestDimReduce.ipynb                   parsec3_3.dat\r\n",
      "Weights1.txt                          w1.txt\r\n",
      "Weights2.txt                          w2.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "### Import Data ###\n",
    "###################\n",
    "\n",
    "# parsec\n",
    "''' Ages used 8.1 to 10.1 steps 0.15'''\n",
    "''' Metallicity used -2.6 to 0.1 steps 0.099'''\n",
    "\n",
    "parsecall = ascii.read('parsec3_3.dat',format='basic', delimiter='\\s')\n",
    "\n",
    "rgb = np.where(parsecall['label']==3)\n",
    "parsec = parsecall[rgb]\n",
    "\n",
    "# r13\n",
    "r13 = fits.getdata('/Users/joshpovick/Desktop/Research/LMC_Ages/lmc_rgbmembers.r13-l33-58672.fits.gz')\n",
    "cln = np.where((r13['FE_H']>-9999.0)&(r13['AK_TARG']>-100.0)&(r13['LOGG']>=0.0)&\n",
    "                (r13['M_H_ERR']>-100.0)&(r13['C_FE']>-100.0)&(r13['N_FE']>-100.0))\n",
    "r13 = r13[cln]\n",
    "\n",
    "# Diane's Ages\n",
    "pdfout = fits.getdata('LMC_DR16_all_PDF.fits.gz', 1)\n",
    "xy, r13_ind, pdfout_ind = np.intersect1d(r13['APOGEE_ID'],pdfout['OBJ'],return_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='20'>\n",
    "    <b>\n",
    "        Create Neural Network\n",
    "    </b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "class Neural_Network(object):\n",
    "    '''\n",
    "    Create a 3 layered (input, hidden, output) feedforward neural network with back propagation and bias. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_width, hidden_width, learning_rate, number_of_epochs):\n",
    "        '''\n",
    "        Parameters:\n",
    "        ----------\n",
    "            input_width: (int) number of nodes in input layer\n",
    "            hidden_width: (int) number of nodes in hidden layer\n",
    "            learning_rate: (float) learning rate \n",
    "            number_of_epochs: (int) how many epochs to use when training\n",
    "        '''\n",
    "        \n",
    "        # Widths of layers\n",
    "        self.InputWidth = input_width\n",
    "        self.HiddenWidth = hidden_width\n",
    "        self.OutputWidth = 1\n",
    "        \n",
    "        # Weights\n",
    "        self.Weights1 = np.random.randn(self.InputWidth,self.HiddenWidth)*0.2\n",
    "        self.Weights2 = np.random.randn(self.HiddenWidth,self.OutputWidth)*0.2\n",
    "        \n",
    "        # Hidden Layer biases\n",
    "        self.b1 = np.random.randn(self.HiddenWidth)\n",
    "        self.b2 = np.random.randn(self.OutputWidth)\n",
    "        \n",
    "        # learning rate\n",
    "        self.eta = learning_rate \n",
    "        \n",
    "        # number of epochs\n",
    "        self.epochs = number_of_epochs\n",
    "        \n",
    "   \n",
    "    # Sigmoid activation function and derivative\n",
    "    def Sigmoid(self,z):\n",
    "        '''\n",
    "        Parameters:\n",
    "        ----------\n",
    "            z: (float) number to plug into sigmoid function\n",
    "        '''\n",
    "        return 1./(1.+np.exp(-np.float128(z)))\n",
    "    \n",
    "    \n",
    "    def DerivSigmoid(self,z):\n",
    "        '''\n",
    "        Parameters:\n",
    "        ----------\n",
    "            z: (float) number to plug into derivative of sigmoid function\n",
    "            sigmoid already applied to z\n",
    "        '''\n",
    "        return self.Sigmoid(z)*(1.-self.Sigmoid(z))\n",
    "#         return z*(1.-z)\n",
    "    \n",
    "    \n",
    "    # Propagation functions\n",
    "    def FeedForward(self,X):\n",
    "        '''\n",
    "        Parameters: \n",
    "        ----------\n",
    "            X: dataset of inputs\n",
    "        '''\n",
    "        # feed through whole neural network\n",
    "        self.First = np.dot(X, self.Weights1) + self.b1\n",
    "        self.Second = self.Sigmoid(self.First)\n",
    "        Third = np.dot(self.Second,self.Weights2) #+ self.b2\n",
    "        \n",
    "        return Third\n",
    "        \n",
    "    \n",
    "    def BackPropagation(self,X,yPredicted,yObserved): \n",
    "        '''\n",
    "        Parameters:\n",
    "        ----------\n",
    "            X: dataset of inputs\n",
    "            yPredicted: known output for X\n",
    "            yObserved: calculated outputs going from input layer to output layer once\n",
    "        '''\n",
    "        # Output layer error and output delta\n",
    "        self.OutputError = yPredicted - yObserved\n",
    "        self.OutputDelta = self.OutputError*self.DerivSigmoid(yObserved)\n",
    "        \n",
    "        # Hidden layer error and hidden delta\n",
    "        self.HiddenError = np.dot(self.OutputDelta,self.Weights2.T)\n",
    "        self.HiddenDelta = self.HiddenError*self.DerivSigmoid(self.First)\n",
    "        #self.HiddenDelta = self.HiddenError*self.DerivSigmoid(self.Second)\n",
    "        \n",
    "        # Update weights \n",
    "        self.Weights1 += self.eta*np.dot(X.T,self.HiddenDelta)\n",
    "        self.Weights2 += self.eta*np.dot(self.Second.T,self.OutputDelta)\n",
    "        \n",
    "#         print(self.b)\n",
    "#         print(np.ones(self.HiddenWidth))\n",
    "#         print(self.HiddenDelta)\n",
    "\n",
    "#         print('bias')\n",
    "#         print(self.b)\n",
    "#         print('bias adjust')\n",
    "#         print(self.HiddenWidth)\n",
    "#         print(self.HiddenDelta)\n",
    "#         print(np.shape(self.HiddenDelta))\n",
    "#         print(self.eta*np.dot(np.ones(self.HiddenWidth).T,self.HiddenDelta))\n",
    "#         print(np.add(self.b,self.eta*np.dot(np.ones(self.HiddenWidth),self.HiddenDelta)))\n",
    "        \n",
    "        # Updates biases\n",
    "        self.b1 += self.eta*np.dot(np.ones(len(self.First)),self.HiddenDelta)\n",
    "#         self.b2 += self.eta*np.dot(np.ones(len(self.FeedForward(X))),self.OutputDelta)\n",
    "#         self.b = self.b + self.eta*np.dot(np.ones(self.HiddenWidth),self.HiddenDelta)\n",
    "#         self.b = np.add(self.b,self.eta*np.dot(np.ones(self.HiddenWidth),self.HiddenDelta))\n",
    "    \n",
    "   \n",
    "    # Train on dataset\n",
    "    def Train(self,X,yPredicted):\n",
    "        '''\n",
    "        Train neural network on data in epochs and print final loss\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "            X: dataset of inputs to train\n",
    "            yPredicted: known output for X\n",
    "        '''\n",
    "        \n",
    "        # feedforward and backpropagate for the specified number of epochs\n",
    "        for i in tqdm_notebook(range(self.epochs)):\n",
    "            self.BackPropagation(X,yPredicted,self.FeedForward(X))\n",
    "        \n",
    "        # print out loss\n",
    "        print('Training Loss (MSE): ', np.mean(np.square(yPredicted - self.FeedForward(X))))\n",
    "        \n",
    "    \n",
    "    # Predict output from new input\n",
    "    def Predict(self,XNew):\n",
    "        '''\n",
    "        Predict the output given a new dataset XNew\n",
    "        '''\n",
    "        return self.FeedForward(XNew)\n",
    "    \n",
    "    \n",
    "    # Utility functions\n",
    "    def SaveWeights(self):\n",
    "        '''\n",
    "        Save weights from the input layer to the hidden layer as 'Weights1.txt'\n",
    "        and save weights from hidden layer to output as 'Weights2.txt'.\n",
    "        '''\n",
    "        np.savetxt('Weights1.txt',self.Weights1,fmt='%s')\n",
    "        np.savetxt('Weights2.txt',self.Weights2,fmt='%s')\n",
    "        np.savetxt('b.txt',self.b1,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "xAll = np.array([parsec['logTe'],parsec['Ksmag'],parsec['MH'],parsec['logg']]).T #np.array(([2, 9], [1, 5], [3, 6], [5, 10]), dtype=float) # input data\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(xAll)\n",
    "# scxAll = scaler.transform(xAll)\n",
    "\n",
    "y = parsec['logAge']/np.max(parsec['logAge']) #np.array(([92], [86], [89]), dtype=float) # output\n",
    "\n",
    "# scale units\n",
    "# xAll = xAll/np.amax(xAll, axis=0) # scaling input data\n",
    "# y = y/100 # scaling output data (max test score is 100)\n",
    "\n",
    "# # split data\n",
    "# X = np.split(xAll, [3])[0] # training data\n",
    "# XNew = np.split(xAll, [3])[1] # testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xAll, y, test_size=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array([parsec['logTe'],parsec['Ksmag'],np.log10(parsec['Zini']/0.02),parsec['logg'],\n",
    "#           np.multiply(parsec['logTe'],parsec['Ksmag']),np.multiply(parsec['logTe'],np.log10(parsec['Zini']/0.02)),\n",
    "#           np.multiply(parsec['logTe'],parsec['logg']),np.multiply(parsec['Ksmag'],np.log10(parsec['Zini']/0.02)),\n",
    "#           np.multiply(parsec['Ksmag'],parsec['logg']),np.multiply(np.log10(parsec['Zini']/0.02),parsec['logg']),\n",
    "#           np.square(parsec['logTe']),np.square(parsec['Ksmag']),np.square(np.log10(parsec['Zini']/0.02)),\n",
    "#           np.square(parsec['logg'])])\n",
    "max(parsec['logAge'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:128: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f220a02927374a0eb5495744df58d3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss (MSE):  logAge    729681.108257\n",
      "dtype: float128\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network(input_width=4,hidden_width=3,learning_rate=0.5,number_of_epochs=100000)\n",
    "NN.Train(pd.DataFrame(X_train),pd.DataFrame(y_train))\n",
    "NN.SaveWeights()\n",
    "# NN.Predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 1.000e+00,\n",
       "        5.000e+00, 8.000e+00, 1.600e+01, 8.934e+03]),\n",
       " array([855.14991929, 855.1499193 , 855.1499193 , 855.1499193 ,\n",
       "        855.1499193 , 855.1499193 , 855.1499193 , 855.1499193 ,\n",
       "        855.1499193 , 855.1499193 , 855.1499193 ], dtype=float128),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(NN.Predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10773</th>\n",
       "      <td>9.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10774</th>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10776</th>\n",
       "      <td>9.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10777</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10778</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10779</th>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10780</th>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10781</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10782</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>9.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10791</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10792</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10793</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10794</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10795</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10796</th>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10797</th>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10798</th>\n",
       "      <td>9.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10801 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       logAge\n",
       "0        9.50\n",
       "1        9.35\n",
       "2        8.60\n",
       "3        9.50\n",
       "4        9.50\n",
       "5        9.50\n",
       "6        8.45\n",
       "7        8.45\n",
       "8        9.20\n",
       "9        9.50\n",
       "10       9.65\n",
       "11       9.35\n",
       "12       8.45\n",
       "13       8.90\n",
       "14       8.00\n",
       "15       9.80\n",
       "16       9.80\n",
       "17       9.35\n",
       "18       9.05\n",
       "19       9.35\n",
       "20       9.20\n",
       "21       9.95\n",
       "22       9.50\n",
       "23       9.50\n",
       "24       9.80\n",
       "25       9.05\n",
       "26       9.80\n",
       "27       8.45\n",
       "28       9.80\n",
       "29       8.90\n",
       "...       ...\n",
       "10771    9.50\n",
       "10772   10.10\n",
       "10773    9.65\n",
       "10774    8.45\n",
       "10775    9.50\n",
       "10776    9.65\n",
       "10777    9.50\n",
       "10778    9.50\n",
       "10779    9.20\n",
       "10780    8.90\n",
       "10781    9.80\n",
       "10782    9.95\n",
       "10783    9.35\n",
       "10784    9.95\n",
       "10785    9.05\n",
       "10786    9.50\n",
       "10787    9.50\n",
       "10788    9.35\n",
       "10789    8.90\n",
       "10790    9.95\n",
       "10791    9.95\n",
       "10792    9.95\n",
       "10793    9.80\n",
       "10794    9.80\n",
       "10795    9.80\n",
       "10796    8.00\n",
       "10797    8.75\n",
       "10798    9.65\n",
       "10799    9.50\n",
       "10800    9.80\n",
       "\n",
       "[10801 rows x 1 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)\n",
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
